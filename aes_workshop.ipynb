{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import common libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import os\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a few paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# path where fake audio files are saved\n",
    "data_path = '/data/Famous_Figures/AES_Data/aes_data'\n",
    "# data_path = '/data/Famous_Figures/AES_Data/aes_data_laundered'\n",
    "\n",
    "# path where features will be saved\n",
    "feat_dir = '/data/Famous_Figures/AES_Features/'\n",
    "# feat_dir = '/data/Famous_Figures/AES_Features_laundered/'\n",
    "\n",
    "# path where score files will be saved\n",
    "score_dir = '/data/Famous_Figures/AES_Score_Files/'\n",
    "# score_dir = '/data/Famous_Figures/AES_Score_Files_laundered/'\n",
    "\n",
    "if not os.path.exists(score_dir):\n",
    "    os.makedirs(score_dir)\n",
    "\n",
    "# extension of the audio files\n",
    "audio_ext = '.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CQCC-GMM and LFCC-GMM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barack_Obama_StyleTTS2', 'Trump_Parrot_1', 'Trump_Parrot_2', 'Joe_Biden_ElevenLabs_1', 'Joe_Biden_ElevenLabs_2', 'Barack_Obama_Original', 'Donald_Trump_Original', 'Joe_Biden_Original']\n",
      "8\n",
      "Using Pickle Features\n",
      "0\n",
      "feature extraction time 0.0017457008361816406\n",
      "(8847, 60)\n",
      "-212.14057060122144\n",
      "-195.1340268100725\n",
      "scoring time 2.6971914768218994\n",
      "total time 2.698937177658081\n",
      "1\n",
      "feature extraction time 0.002247333526611328\n",
      "(3379, 60)\n",
      "-181.0426718337663\n",
      "-179.3783592590101\n",
      "scoring time 0.22828459739685059\n",
      "total time 0.23053193092346191\n",
      "2\n",
      "feature extraction time 0.0010013580322265625\n",
      "(3921, 60)\n",
      "-179.48302739260288\n",
      "-178.32889375108923\n",
      "scoring time 0.25702691078186035\n",
      "total time 0.2580282688140869\n",
      "3\n",
      "feature extraction time 0.0013890266418457031\n",
      "(3894, 60)\n",
      "-184.77277295402538\n",
      "-184.57112419628515\n",
      "scoring time 0.2601461410522461\n",
      "total time 0.2615351676940918\n",
      "4\n",
      "feature extraction time 0.0014374256134033203\n",
      "(4737, 60)\n",
      "-189.61500614556363\n",
      "-189.10915755566052\n",
      "scoring time 0.28650474548339844\n",
      "total time 0.28794217109680176\n",
      "5\n",
      "feature extraction time 0.0009851455688476562\n",
      "(4888, 60)\n",
      "-179.75952020961824\n",
      "-179.49258338034042\n",
      "scoring time 0.28093957901000977\n",
      "total time 0.2819247245788574\n",
      "6\n",
      "feature extraction time 0.0013623237609863281\n",
      "(4888, 60)\n",
      "-184.78631695782832\n",
      "-185.47691414243315\n",
      "scoring time 0.3613767623901367\n",
      "total time 0.36273908615112305\n",
      "7\n",
      "feature extraction time 0.001405954360961914\n",
      "(4888, 60)\n",
      "-181.34643760713595\n",
      "-180.944963197369\n",
      "scoring time 0.2778012752532959\n",
      "total time 0.2792072296142578\n"
     ]
    }
   ],
   "source": [
    "from ASD_ML.gmm_asvspoof import scoring\n",
    "\n",
    "features = 'cqcc'\n",
    "model_dir = 'ASD_ML/gmm_' + str(512) + '_LA_' + features\n",
    "bona_path = os.path.join(model_dir, 'bonafide', 'gmm_final.pkl')\n",
    "spoof_path = os.path.join(model_dir, 'spoof', 'gmm_final.pkl')\n",
    "\n",
    "dict_file = dict()\n",
    "dict_file['bona'] = bona_path\n",
    "dict_file['spoof'] = spoof_path\n",
    "\n",
    "# files = ['Barack_Obama_StyleTTS2', 'Trump_Parrot_1', 'Trump_Parrot_2', 'Joe_Biden_ElevenLabs_1', 'Joe_Biden_ElevenLabs_2']\n",
    "files = os.listdir(data_path)\n",
    "files = [f.split('.')[0] for f in files]\n",
    "\n",
    "eval_folder = data_path\n",
    "\n",
    "scores_file = os.path.join(score_dir, 'scores-' + features + '-gmm-' + str(512) + '.txt')\n",
    "\n",
    "test_scores = scoring(scores_file=scores_file, dict_file=dict_file, features=features,\n",
    "        eval_file_list=files, eval_folder=eval_folder, audio_ext=audio_ext,\n",
    "        feat_dir=feat_dir, features_cached=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    files     scores\n",
      "0  Barack_Obama_StyleTTS2 -17.006544\n",
      "1          Trump_Parrot_1  -1.664313\n",
      "2          Trump_Parrot_2  -1.154134\n",
      "3  Joe_Biden_ElevenLabs_1  -0.201649\n",
      "4  Joe_Biden_ElevenLabs_2  -0.505849\n",
      "5   Barack_Obama_Original  -0.266937\n",
      "6   Donald_Trump_Original   0.690597\n",
      "7      Joe_Biden_Original  -0.401474\n"
     ]
    }
   ],
   "source": [
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OC-Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature file Barack_Obama_StyleTTS2 already extracted\n",
      "Feature file Trump_Parrot_1 already extracted\n",
      "Feature file Trump_Parrot_2 already extracted\n",
      "Feature file Joe_Biden_ElevenLabs_1 already extracted\n",
      "Feature file Joe_Biden_ElevenLabs_2 already extracted\n",
      "(60, 667)\n",
      "(60, 667)\n",
      "(60, 667)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 750])\n",
      "torch.Size([1, 1, 60, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_610262/1858804375.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score = F.softmax(lfcc_outputs)[:, 0]\n",
      "100%|██████████| 8/8 [00:00<00:00, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 750])\n",
      "torch.Size([1, 1, 60, 750])\n",
      "torch.Size([60, 750])\n",
      "torch.Size([1, 1, 60, 750])\n",
      "torch.Size([60, 750])\n",
      "torch.Size([1, 1, 60, 750])\n",
      "torch.Size([60, 750])\n",
      "torch.Size([1, 1, 60, 750])\n",
      "torch.Size([60, 750])\n",
      "torch.Size([1, 1, 60, 750])\n",
      "torch.Size([60, 750])\n",
      "torch.Size([1, 1, 60, 750])\n",
      "torch.Size([60, 750])\n",
      "torch.Size([1, 1, 60, 750])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "############## imports #############\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append(\"./AIR-ASVspoof/\")\n",
    "from process_LA_data import extract_lfcc\n",
    "\n",
    "############## Paths and Variables ###############\n",
    "\n",
    "# filelist = ['Barack_Obama_StyleTTS2', 'Trump_Parrot_1', 'Trump_Parrot_2', 'Joe_Biden_ElevenLabs_1', 'Joe_Biden_ElevenLabs_2']\n",
    "# labels = [\"spoof\", \"spoof\", \"spoof\", \"spoof\", \"spoof\"]\n",
    "\n",
    "files = os.listdir(data_path)\n",
    "filelist = [f.split('.')[0] for f in files]\n",
    "labels = [\"spoof\" for _ in range(len(filelist))]\n",
    "\n",
    "model_dir = \"./AIR-ASVspoof/models/ocsoftmax\"\n",
    "model_path = os.path.join(model_dir, \"anti-spoofing_lfcc_model.pt\")\n",
    "loss_model_path = os.path.join(model_dir, \"anti-spoofing_loss_model.pt\")\n",
    "\n",
    "add_loss =  \"ocsoftmax\"\n",
    "\n",
    "Feat_dir = os.path.join(feat_dir, 'lfcc_features_airasvspoof')\n",
    "LFCC_sav_dir = os.path.join(Feat_dir, 'eval')\n",
    "audio_ext = '.wav'\n",
    "\n",
    "if not os.path.exists(LFCC_sav_dir):\n",
    "    os.makedirs(LFCC_sav_dir)\n",
    "\n",
    "#################### Extract Features ######################\n",
    "for file in filelist:\n",
    "\n",
    "    LFCC_filename = os.path.join(LFCC_sav_dir, str(file) + '.pkl')\n",
    "\n",
    "    if not os.path.exists(LFCC_filename):\n",
    "\n",
    "        # audio_file = os.path.join(pathToDatabase, 'ASVspoof2019_' + access_type + '_eval/flac', file + '.flac')\n",
    "        audio_file = os.path.join(data_path, str(file) + audio_ext)\n",
    "\n",
    "        x, fs = librosa.load(audio_file)\n",
    "        \n",
    "        lfcc_featues = extract_lfcc(x, fs)\n",
    "\n",
    "        print(lfcc_featues.shape)\n",
    "\n",
    "        with open(LFCC_filename, 'wb') as f:\n",
    "            pickle.dump(lfcc_featues, f)\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"Feature file {} already extracted\".format(file))\n",
    "\n",
    "\n",
    "#################### Generate Scores ######################\n",
    "\n",
    "def repeat_padding(spec, ref_len):\n",
    "    mul = int(np.ceil(ref_len / spec.shape[1]))\n",
    "    spec = spec.repeat(1, mul)[:, :ref_len]\n",
    "    return spec\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torch.load(model_path, map_location=\"cuda\")\n",
    "model = model.to(device)\n",
    "loss_model = torch.load(loss_model_path) if add_loss != \"softmax\" else None\n",
    "\n",
    "model.eval()\n",
    "\n",
    "scr = []\n",
    "\n",
    "with open(os.path.join(score_dir, 'AES_Workshop_checkpoint_cm_score.txt'), 'w') as cm_score_file:\n",
    "\n",
    "    for i, audio_fn in enumerate(tqdm(filelist)):\n",
    "\n",
    "        LFCC_filename = os.path.join(LFCC_sav_dir, str(audio_fn) + '.pkl')\n",
    "        \n",
    "        with open(LFCC_filename, 'rb') as feature_handle:\n",
    "            feat_mat = pickle.load(feature_handle)\n",
    "\n",
    "        feat_mat = torch.from_numpy(feat_mat)\n",
    "        feat_len = 750\n",
    "        this_feat_len = feat_mat.shape[1]\n",
    "        if this_feat_len > feat_len:\n",
    "            startp = np.random.randint(this_feat_len-feat_len)\n",
    "            feat_mat = feat_mat[:, startp:startp+feat_len]\n",
    "        if this_feat_len < feat_len:\n",
    "            \n",
    "            feat_mat = repeat_padding(feat_mat, feat_len)\n",
    "\n",
    "        print(feat_mat.shape)\n",
    "\n",
    "        # lfcc_feat = feat_mat.unsqueeze(1).float()\n",
    "        # print(lfcc_feat.shape)\n",
    "        lfcc_feat = feat_mat.unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "        print(lfcc_feat.shape)\n",
    "        \n",
    "        label = labels[i]\n",
    "\n",
    "        feats, lfcc_outputs = model(lfcc_feat)\n",
    "\n",
    "        score = F.softmax(lfcc_outputs)[:, 0]\n",
    "\n",
    "        if add_loss == \"ocsoftmax\":\n",
    "            ang_isoloss, score = loss_model(feats, labels)\n",
    "        elif add_loss == \"amsoftmax\":\n",
    "            outputs, moutputs = loss_model(feats, labels)\n",
    "            score = F.softmax(outputs, dim=1)[:, 0]\n",
    "\n",
    "        \n",
    "        cm_score_file.write(\n",
    "            '%s %s %s\\n' % (audio_fn, label, score.item()))\n",
    "    \n",
    "        scr.append(score.item())\n",
    "\n",
    "scores_df_ocsoftmax = pd.DataFrame({'files': filelist, 'scores': scr})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    files    scores\n",
      "0  Barack_Obama_StyleTTS2 -0.464083\n",
      "1          Trump_Parrot_1 -0.966226\n",
      "2          Trump_Parrot_2 -0.960892\n",
      "3  Joe_Biden_ElevenLabs_1 -0.579996\n",
      "4  Joe_Biden_ElevenLabs_2 -0.381004\n",
      "5   Barack_Obama_Original  0.392821\n",
      "6   Donald_Trump_Original  0.926789\n",
      "7      Joe_Biden_Original  0.676511\n"
     ]
    }
   ],
   "source": [
    "print(scores_df_ocsoftmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RawNet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Model loaded : ./RawNet2/models/pre_trained_DF_RawNet2.pth\n",
      "no. of eval trials 8\n",
      "torch.Size([64600])\n",
      "torch.Size([1, 64600])\n",
      "[-9.343414306640625]\n",
      "torch.Size([64600])\n",
      "torch.Size([1, 64600])\n",
      "[-9.343414306640625, -8.581969261169434]\n",
      "torch.Size([64600])\n",
      "torch.Size([1, 64600])\n",
      "[-9.343414306640625, -8.581969261169434, -12.180954933166504]\n",
      "torch.Size([64600])\n",
      "torch.Size([1, 64600])\n",
      "[-9.343414306640625, -8.581969261169434, -12.180954933166504, -0.3218999207019806]\n",
      "torch.Size([64600])\n",
      "torch.Size([1, 64600])\n",
      "[-9.343414306640625, -8.581969261169434, -12.180954933166504, -0.3218999207019806, -0.0006618693005293608]\n",
      "torch.Size([64600])\n",
      "torch.Size([1, 64600])\n",
      "[-9.343414306640625, -8.581969261169434, -12.180954933166504, -0.3218999207019806, -0.0006618693005293608, -0.24718056619167328]\n",
      "torch.Size([64600])\n",
      "torch.Size([1, 64600])\n",
      "[-9.343414306640625, -8.581969261169434, -12.180954933166504, -0.3218999207019806, -0.0006618693005293608, -0.24718056619167328, -0.4526483416557312]\n",
      "torch.Size([64600])\n",
      "torch.Size([1, 64600])\n",
      "[-9.343414306640625, -8.581969261169434, -12.180954933166504, -0.3218999207019806, -0.0006618693005293608, -0.24718056619167328, -0.4526483416557312, -10.246075630187988]\n",
      "Scores saved to /data/Famous_Figures/AES_Score_Files/RawNet2__eval_CM_scores.txt\n"
     ]
    }
   ],
   "source": [
    "############## imports ##########\n",
    "import yaml\n",
    "import librosa\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "sys.path.append(\"./RawNet2/\")\n",
    "from model import RawNet\n",
    "\n",
    "############# Paths and Variables #############\n",
    "\n",
    "# file_eval = ['Barack_Obama_StyleTTS2', 'Trump_Parrot_1', 'Trump_Parrot_2', 'Joe_Biden_ElevenLabs_1', 'Joe_Biden_ElevenLabs_2']\n",
    "# labels = [\"spoof\", \"spoof\", \"spoof\", \"spoof\", \"spoof\"]\n",
    "\n",
    "files = os.listdir(data_path)\n",
    "file_eval = [f.split('.')[0] for f in files]\n",
    "labels = [\"spoof\" for _ in range(len(file_eval))]\n",
    "\n",
    "eval_out = os.path.join(score_dir, 'RawNet2_' + '_eval_CM_scores.txt')\n",
    "model_path = './RawNet2/models/pre_trained_DF_RawNet2.pth'\n",
    "\n",
    "############# Black Box Code ############\n",
    "\n",
    "dir_yaml = os.path.splitext('./RawNet2/model_config_RawNet')[0] + '.yaml'\n",
    "\n",
    "with open(dir_yaml, 'r') as f_yaml:\n",
    "    parser1 = yaml.load(f_yaml, yaml.Loader)\n",
    "\n",
    "\n",
    "track = 'LA'\n",
    "assert track in ['LA', 'PA','DF'], 'Invalid track given'\n",
    "\n",
    "#GPU device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'                  \n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "#model \n",
    "model = RawNet(parser1['model'], device)\n",
    "nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "model =(model).to(device)\n",
    "\n",
    "#set Adam optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=args.lr,weight_decay=args.weight_decay)\n",
    "\n",
    "if model_path:\n",
    "    model.load_state_dict(torch.load(model_path,map_location=device))\n",
    "    print('Model loaded : {}'.format(model_path))\n",
    "\n",
    "print('no. of eval trials',len(file_eval))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# functions we may need\n",
    "def pad(x, max_len=64600):\n",
    "    x_len = x.shape[0]\n",
    "    if x_len >= max_len:\n",
    "        return x[:max_len]\n",
    "    # need to pad\n",
    "    num_repeats = int(max_len / x_len)+1\n",
    "    padded_x = np.tile(x, (1, num_repeats))[:, :max_len][0]\n",
    "    \n",
    "    return padded_x\t\n",
    "\n",
    "score_list = []  \n",
    "\n",
    "for utt_id, audio_fn in enumerate(file_eval):\n",
    "\n",
    "    X, fs = librosa.load(os.path.join(data_path, str(audio_fn) + audio_ext), sr=16000)\n",
    "    \n",
    "    X_pad = pad(X, 64600)\n",
    "    x_inp = Tensor(X_pad)\n",
    "\n",
    "    print(x_inp.shape)\n",
    "\n",
    "    x_inp = x_inp.unsqueeze(0).float().to(device)\n",
    "\n",
    "    print(x_inp.shape)\n",
    "    \n",
    "    score_out = model(x_inp)\n",
    "\n",
    "    score_out = (score_out[:, 1]).data.cpu().numpy().ravel()\n",
    "\n",
    "    # add outputs\n",
    "    score_list.extend(score_out.tolist())\n",
    "\n",
    "    print(score_list)\n",
    "    \n",
    "with open(eval_out, 'a+') as fh:\n",
    "    for f, cm in zip(file_eval,score_list):\n",
    "        fh.write('{} {}\\n'.format(f, cm))\n",
    "fh.close()   \n",
    "print('Scores saved to {}'.format(eval_out))\n",
    "\n",
    "scores_df_rawnet2 = pd.DataFrame({'files': file_eval, 'scores': score_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    files     scores\n",
      "0  Barack_Obama_StyleTTS2  -9.343414\n",
      "1          Trump_Parrot_1  -8.581969\n",
      "2          Trump_Parrot_2 -12.180955\n",
      "3  Joe_Biden_ElevenLabs_1  -0.321900\n",
      "4  Joe_Biden_ElevenLabs_2  -0.000662\n",
      "5   Barack_Obama_Original  -0.247181\n",
      "6   Donald_Trump_Original  -0.452648\n",
      "7      Joe_Biden_Original -10.246076\n"
     ]
    }
   ],
   "source": [
    "print(scores_df_rawnet2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "\n",
    "score_file_path = '/data/Famous_Figures/AES_Score_Files/'\n",
    "score_file_path_laundered = '/data/Famous_Figures/AES_Score_Files_laundered/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Score files of CQCC-GMM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'scores-cqcc-gmm-512.txt'\n",
    "\n",
    "scores_fulfile = os.path.join(score_file_path, filename)\n",
    "scores_fulfile_laundered = os.path.join(score_file_path_laundered, filename)\n",
    "\n",
    "scores_df = pd.read_csv(scores_fulfile, sep=\" \", names=[\"AUDIO_FILE_NAME\", \"Scores\"])\n",
    "\n",
    "scores_df_laundered = pd.read_csv(scores_fulfile_laundered, sep=\" \", names=[\"AUDIO_FILE_NAME\", \"Scores\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_styler = scores_df.style.set_table_attributes(\"style='display:inline'\").set_caption('Before Laundering')\n",
    "df2_styler = scores_df_laundered.style.set_table_attributes(\"style='display:inline'\").set_caption('After Laundering')\n",
    "\n",
    "display_html(df1_styler._repr_html_()+df2_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Score files of OC-Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'AES_Workshop_checkpoint_cm_score.txt'\n",
    "\n",
    "scores_fulfile = os.path.join(score_file_path, filename)\n",
    "scores_fulfile_laundered = os.path.join(score_file_path_laundered, filename)\n",
    "\n",
    "scores_df = pd.read_csv(scores_fulfile, sep=\" \", names=[\"AUDIO_FILE_NAME\", \"Key\", \"Scores\"])\n",
    "\n",
    "scores_df_laundered = pd.read_csv(scores_fulfile_laundered, sep=\" \", names=[\"AUDIO_FILE_NAME\", \"Key\", \"Scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_styler = scores_df.style.set_table_attributes(\"style='display:inline'\").set_caption('Before Laundering')\n",
    "df2_styler = scores_df_laundered.style.set_table_attributes(\"style='display:inline'\").set_caption('After Laundering')\n",
    "\n",
    "display_html(df1_styler._repr_html_()+df2_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Score files of RawNet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'RawNet2__eval_CM_scores.txt'\n",
    "\n",
    "scores_fulfile = os.path.join(score_file_path, filename)\n",
    "scores_fulfile_laundered = os.path.join(score_file_path_laundered, filename)\n",
    "\n",
    "scores_df = pd.read_csv(scores_fulfile, sep=\" \", names=[\"AUDIO_FILE_NAME\", \"Scores\"])\n",
    "\n",
    "scores_df_laundered = pd.read_csv(scores_fulfile_laundered, sep=\" \", names=[\"AUDIO_FILE_NAME\", \"Scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_styler = scores_df.style.set_table_attributes(\"style='display:inline'\").set_caption('Before Laundering')\n",
    "df2_styler = scores_df_laundered.style.set_table_attributes(\"style='display:inline'\").set_caption('After Laundering')\n",
    "\n",
    "display_html(df1_styler._repr_html_()+df2_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
